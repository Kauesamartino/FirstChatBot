# -*- coding: utf-8 -*-
"""ChatBotGeminiAPI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HfI-cgTY1AX4zUhl8eBZQYRiNgel9jTN
"""

# Instalando SDK do Google

!pip install -U -q google-generativeai

# Configurando API Key

import google.generativeai as genai

GOOGLE_API_KEY="COLE SUA API"
genai.configure(api_key=GOOGLE_API_KEY)

# Listando modelos disponíveis

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

# Definindo configurações gerais

generation_config = {
    "candidate_count": 1,
    "temperature": 0.5,
}

# Definindo configurações de segurança

safety_settings={
    "HARASSMENT": "BLOCK_NONE",
    "HATE": "BLOCK_NONE",
    "SEXUAL": "BLOCK_NONE",
    "DANGEROUS": "BLOCK_NONE",
}

# Inicializando modelo

model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                              generation_config=generation_config,
                              safety_settings=safety_settings)

# Iniciando chat

chat = model.start_chat(history=[])

prompt = input("Esperando prompt: ")

while prompt != "fim":
  response = chat.send_message(prompt)
  print("Resposta: ", response.text, "\n")
  prompt = input("Esperando prompt: ")

# Melhorando a visualização do histórico
import textwrap
from IPython.display import display
from IPython.display import Markdown

def to_markdown(text):
  text = text.replace('\n', '  \n')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

#Imprimindo o histórico
for message in chat.history:
  display(to_markdown(f"**{message.role}:** {message.parts[0].text}"))
print()